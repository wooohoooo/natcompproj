{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 15 to  max 20 pages document. The report should include:\n",
    "\n",
    "• Specific goals of the work.\n",
    "\n",
    "• Review of related work.\n",
    "\n",
    "• Description of your testing procedures.\n",
    "\n",
    "• Description of the algorithms used. Ensure that the work is reproducible given your\n",
    "description.\n",
    "\n",
    "• Results. Ensure to perform a correct experimental analysis (e.g. repeated experiments,\n",
    "statistical analysis of results).\n",
    "\n",
    "• Conclusion. Is your line of work worth pursuing? What additional enhancements could be made?\n",
    "\n",
    "• A short description of the contribution and self-evaluation of each member of the team\n",
    "\n",
    "• URL address where we can find implementation of algorithms developed and used during the project: 1) source code, together with all data necessary to run the program and a short manual describing how to use/run the program, and 2) a sample run, screenshot, or other indication of system behaviour.\n",
    "\n",
    "Deadline: 20 June."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific Goals of the Work\n",
    "\n",
    "**Why Models?**\n",
    "Machine Learning (ML) is often used to facilitate decision making. Knowing what value a product is likely to have in certain market, for example, is going to influence pricing, marketing and future planning. These kinds of predictions are plentiful, and modern ML has come a long way from (only) being able to predict linear relationships between variables to superior models such as complex decision trees, that can model complicated combinations and interactions between features.\n",
    "\n",
    "**Why Uncertainty?**\n",
    "However, classically and due to certain restrictions such as tractability, ML has been focussed on predicting a point value rather than a range of values; while this is enough to make decisions in which do not depend in the actual value too much, it is a great restriction for situations in which we want to make a decision that is as well-informed as possible. \n",
    "In a situation like this, we would prefer not only a point estimate, but also an estimation of *how likely it is that the actual value is going to fall close to this point*. Imagine making the decision of selling a house: the seller would be more at ease with his sale knowing that the outcome will likely fall between 480.000 and 520.000 than if the prediction is just 'something between one and a million'. Essentially, what we try to capture with this spread of values (one particular implementation of this concept is the *standard deviation* of a normal distribution) is the *risk* we are taking by relying on the prediction. This obviously has other use cases, be it in medicine, game-playing or any other kind of situation that involves committing to one course of action over another. \n",
    "\n",
    "One of the more infuential branches of statistical thinking, so called Bayesianism, has promoted the need for having a full distribution over possible values, and with it predictive uncertainty, for years and years. However, while bayesian models exist (there are equivalents for linear regression for example) and things like Bayesian Networks and Gaussian Processes rival 'classical, or 'frequentist' approaches on a regular basis, they come with certain limitations, such as necessitating the specification of a prior as well as intractability for more complext models. \n",
    "\n",
    "**What are Ensembles?**\n",
    "In recent years, two particular branches of machine learning have gathered wide spread attention: So-called 'Deep Learning', which in its roots intended to mimic the human brain by constructing vast networks of artificial neurons that propagate signals through different layers until a prediction is found (others have called them stacked logistic regressions, and there is a point to be made for this particular description, too). The other are ensembles, groups of models that are combined in order to make a better prediction than any one model would be able to alone (see the computation of why they are better in voing for example; see Concordets Jury theorem). [Footnote: There seem to be deep connection between ensembling and certain kinds of neural network mehtodologies, such as dropout, which is sometimes referred to as 'ensembling with extreme parameter sharing'. This will be interesting in the discussion].\n",
    "While Deep Learning gathers all the (public) interest of research and media, ensembling has established itself as a collection of methods that are being used in practice as well as in ML competitions; as is evident by posts like this one: https://www.datasciencecentral.com/profiles/blogs/want-to-win-at-kaggle-pay-attention-to-your-ensembles.\n",
    "\n",
    "**what is this work about**\n",
    "After reviewing a sample from the literature on ensembling, uncertainty and the combination of both, the current project aims to investigate the possibility to extract uncertainty information from ensembles in regression in addition to a point estimate of the predictive value. In order to do so, a very simple addtion is being made: When computing the predictive mean by averaging the predictions of the ensemble members, we also compute the standard deviation of this sample of predictions in order to obtain an approximation of the dostribution over values that the ensemble would deem likely. This way of obtaining uncertainty does not suffer limitations which has long plagued approaches that utilise full distributions over parameters (see bayesian models), such as intractability. The uncertainty that is obtained that way is being tested with several indicator values on the 'quality of uncertainty' that is being delivered.\n",
    "Additionally, in the discussion part, some more intricate consequences of this approach are being spproached, including a short primer on priors on ensembles as well as on what kinds of uncertainty we are reporting in our case and finally, an outlook on how this methodology might be used in combination with complex models such as deep learning, what the addition of uncertainty could bring to the table in applications and finally, how this work could be improved upon.\n",
    "\n",
    "\n",
    "# THIS IS approximately one page\n",
    "\n",
    "[such as: WHAT DOES THIS MEAN? this is a distribution over how likely the model thinks the values are, obviously this changes a lot when we change the model (see e.g. the mixed model ensemble with and without linear component!), how do we utilise the information to e.g. choose ensemble members (adding and removing members from this prediction is easy - just do or do not use their prediction in the final outcome). This could be determined e.g. by seeing if both the error of the ensemble goes down by removing the member, but also by looking at the quality of uncertainty before and after - removing a member that contributes to error but also makes sure the predictive uncertainty is more finely attuned to the case might indicate that it DOES indeed have some information that is useful in many contexts).]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "- use the teachings on Ensembles (a number of experts who's opinion is combined to increase the probability of it being correct) to estimate the uncertainty within which the predicted value is going to fall\n",
    "\n",
    "- Die Berechnung der Likelihood of combination of experts being correct vs how it scales with group size\n",
    "\n",
    "- Why Uncertainty? Agents! See Academic Writing sample\n",
    "\n",
    "\n",
    "\n",
    "The difference between statistical modelling and machine learning is generally not well defined. Both gain insights form large amounts of data and both utilise complex models in order to make their predictions. \n",
    "\n",
    "One of the possible differences is that Statistical Modelling generally depends on the existence of fully specified distributions, while Machine Learning in general is more concerned with point-estimation of target values. \n",
    "However, a few approaches seem to be able to combine the benefits of both approaches. These approaches, generally spearheaded by bayesian scientists (who are uncomfortable with point estimations in general, as they always want to know a full distribution over predictions).\n",
    "\n",
    "\n",
    "- Uncertainty is important for decision making\n",
    "\n",
    "- See eg. the online bootstrap for explanation why, or Agrawal, S., Com, S., Goyal, N., Mannor, S., Srebro, N., & Williamson, R. C. (2012). Analysis of Thompson Sampling for the Multi-armed Bandit Problem, 2326(39), 1–39. Retrieved from http://proceedings.mlr.press/v23/agrawal12/agrawal12.pdf\n",
    "\n",
    "- difference between statistical modelling and machine learning ~ uncertainty\n",
    "\n",
    "- Two approaches:\n",
    "\n",
    "- Bayesian Approaches to Uncertainty: Fully specified distribution - although most of the time it's approximated because fully bayesian methods are expensive; so what we usually have is either variational bayes or MCMC\n",
    "\n",
    "- Frequentist Approach to uncertainty:  ‘confidence interval’ (see https://www.bipm.org/cc/CCT/Allowed/26/Disentangling_uncertainty_v14.pdf)\n",
    "\n",
    "- Ensemble is a method where the prediction of many different models are combined to produce a more elaborate prediction (Find a standard text on ensembles - in the course?)\n",
    "\n",
    "- Ensembles are very much like asking different experts their opinion in order to find a more likely true prediction (look at the berechnung in one of the assignments)\n",
    "\n",
    "- Thus theoretically, we can assume that no single expert holds the truth, but we can assume that since different experts have different opinions that are all somewhat grounded in truth, the real model BZW THE BEST POSSIBLE MODEL GIVEN THE DATA AND FORMALISMS we have in place is somewhere betweeen the opinions. Thus we take the predictive mean - the mean of all the predictions - and use that as our final prediction. However, it is possible to extract uncertainty information from this group of experts: If they are all kind of recommending the same thing, it is likely that the optimal recommendation is somewhere close to the value. If all eperts vastly disagree, we can assume that there is not enough information in the Data they have seen, or that the structure of their studies isn't enough, or that there is something wrong otherwise. It is likely that each of them is either basing their decision on wrong data or that they are just randomly guessing (and pretending to know VERY well what they are talking about, as is some experts style).\n",
    "\n",
    "- This is reflected when we don't only take the mean of the prediction of our Ensemble but also it's standard deviation.\n",
    "\n",
    "- Thus we can easily infer the uncertainty of our model with almost no extra computaional cost.\n",
    "\n",
    "- Important: the models need to be sufficiently different in order for this to be a valid method. ASking an expert, his best friend and ten of their studendts might falsely lead to a very confident clique of experts.\n",
    "\n",
    "- to test for this, use predictive power of one member on the others divided by the predictive power of one ensemble member on the error of the ensemble?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of related work\n",
    "\n",
    "The review part will be split up in three parts:\n",
    "\n",
    "- literature that focusses on ensembles, to get a general feel for how they work\n",
    "\n",
    "- literature that focusses on uncertainty of quality measures for uncertainty\n",
    "\n",
    "- literature that combines both\n",
    "\n",
    "\n",
    "### work that focusses on Ensembles\n",
    "\n",
    "Put in:\n",
    "\n",
    "Ensemble definition.\n",
    "**What is an Ensemble**\n",
    "\n",
    "Different ways of combining ensembles.\n",
    "**Voting, Concordet, mean, median, majority, weighted**\n",
    "\n",
    "Explain Different ways of training ensembles.\n",
    "**subspace, bootstrap (63%), mix of models, forest, shuffle data**\n",
    "\n",
    "- Kuncheva, L. I. (2004). Combining Pattern Classifers. Methods and Algorithms.\n",
    "Wiley, Chichester. Chapter 4 & 5.\n",
    "\n",
    "- Ho, T. K. (1998). The random subspace method for constructing decision\n",
    "forests. IEEE transactions on pattern analysis and machine intelligence,\n",
    "20(8), 832-844.\n",
    "\n",
    "### work that focusses on Uncertainty or quality of uncertainty\n",
    "\n",
    "Uncertainty definition\n",
    "**what is uncertainty**\n",
    "\n",
    "Predictive Uncertainty definition\n",
    "**What is predictive Uncertainty**\n",
    "\n",
    "How is uncertainty classically displayed?\n",
    "**Normal Distribution of errors, **\n",
    "\n",
    "Aleatoric vs Epistemic Uncertainty\n",
    "**Which one do we have? Could we theoretically test for one or the other?**\n",
    "\n",
    "Out of Sample Distributions\n",
    "**What is it, how do we do it in Regression**\n",
    "\n",
    "Callibration\n",
    "**What is Calibration, how dot we compute it**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Renard, B., Kavetski, D., Kuczera, G., Thyer, M., & Franks, S. W. (2010). Understanding predictive uncertainty in hydrologic modeling: The challenge of identifying input and structural errors. Water Resour. Res, 46. http://doi.org/10.1029/2009WR008328\n",
    "\n",
    "- Kiureghian, A. Der, & Ditlevsen, O. (2009). Aleatory or epistemic? Does it matter? Structural Safety, 31(2), 105–112. http://doi.org/10.1016/J.STRUSAFE.2008.06.020\n",
    "\n",
    "\n",
    "- Tashman, L. (2000). Out -of-sample tests of forecasting accuracy:ananalysisandreview. International Journal of Forecasting, 16, 437–450. Retrieved from https://www.researchgate.net/profile/Len_Tashman/publication/247087596_Out-of_sample_tests_of_forecasting_accuracy_a_tutorial_and_review/links/5745ceec08ae9f741b430de3.pdf\n",
    "\n",
    "- Willink, R., & White, R. (n.d.). Disentangling Classical and Bayesian Approaches to Uncertainty Analysis. Retrieved from https://www.bipm.org/cc/CCT/Allowed/26/Disentangling_uncertainty_v14.pdf\n",
    "\n",
    "### work that focusses on Ensembles and Uncertainty\n",
    "\n",
    "What work has been done before?\n",
    "**This idea isnt new it appears**\n",
    "\n",
    "Difference between Bayes and Frequentist. \n",
    "**Why is Ensembling a Bayesian Method?**\n",
    "\n",
    "Deep Learning shows some promising ideas\n",
    "**Dropout Networks are Ensembles with extreme parameter sharing**\n",
    "\n",
    "- Characterizing and Visualizing Predictive Uncertainty in Numerical Ensembles Through Bayesian Model Averaging. (n.d.). Retrieved from http://graphics.cs.ucdavis.edu/~joy/NSF-IIS-1018097/Papers/Vis13_175.pdf\n",
    "\n",
    "- Adding Uncertainty to Deep Learning – Towards Data Science. (n.d.). Retrieved June 6, 2018, from https://towardsdatascience.com/adding-uncertainty-to-deep-learning-ecc2401f2013\n",
    "\n",
    "- Parker, W. S. (2013). Ensemble modeling, uncertainty and robust predictions. Wiley Interdisciplinary Reviews: Climate Change, 4(3), 213–223. http://doi.org/10.1002/wcc.220\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of Testing procedures\n",
    "\n",
    "Focus on regression due to personal interest.\n",
    "**little work on uncertainty in regression tasks altough they seem very important to the author**\n",
    "\n",
    "Mean averaging, additionally computing the standard deviation of the sample\n",
    "**after obtaining a sample of predictions from each member of the ensemble, the standard is to compute the average of the samples to obtain the predictive mean. In this case, we add a computation of the standard deviation (which is trivial and one line of code). We report both the predictive mean as well as the standard deviation of the ensemble output. This can be seen as predictive mean and preditive uncertainty**\n",
    "\n",
    "5 ways of generating uncertainty\n",
    "**generating uncertainty from a pre trained ensemble is trivial, as we have seen in the previous paragraph. However, during training time we have to ensure a group of models that is sufficiently different from each other to obtain different values of prediction that we can then use to compute the standard deviation (hving the same value we would not be able to compute this). Several kinds of predictors are very [anfaellig] for different initial conditions, most prominently Neural Networks. However, there are other ways of making sure our experts are sufficiently specialised:**\n",
    "\n",
    "- Bootstrapping n datasets from the original training set. As explained above, this is done by drawing from the original data with replacement and results in n models that are trained on similar but different datasets on which different models of the same type cam be trained to obtain different predictions (essentially with emphasis on different parts of the dataset)\n",
    "\n",
    "- subspace sapling. As explained above, this technique randomly ignores dimensions from the dataset for each of the n predictors. Similarly to bootstrap, this results in ensemble members that are trained on slightly different information and thus give different predictions **THIS IS VERY SIMILAR TO DROPOUT!!!!!!!** Obviusly, this technique can only be used in Datasets that have dim(X) > 1, otherwise there are not enough dimensions to drop it out.\n",
    "\n",
    "- Random Shuffling of Data. As explained above, certain methods are very [anfaellig] to the [reihenfolge] in which the datapoints are presented. Again, one of the most prominent ones are Neural Networks. However, we tried it with different kinds of other models.\n",
    "\n",
    "- Mix of Models. As explained above, it is possible to form an ensemble from completely different kinds of models. In our case, due to the scope of this project, we focussed on [this and that and those], however, theoretically there is no limit in what models can be used. Interestingly, even the same model type with different specifications (deep vs shallow neural nets, Forests of different depths, etc) can be used in this form, which can be seen as the [parent, uebergeordnet, super()] of all the other models which are special cases of this one.\n",
    "\n",
    "ways of quantifying uncertainty\n",
    "**cross validation for every value, out of sample prediction (extreme values that are not reflected in the training data), coverage probability, calibration, correlation between uncertainty and error**\n",
    "\n",
    "Datasets\n",
    "**Two toy datasets, of which one is nonlinear, Boston Housing as multidimensional, real life test case. Explain what it is in detail**\n",
    "\n",
    "Statistical [Auswertung]: \n",
    "**each of the experiments has been performed 100 times, we report the outcomes of each of them. If not otherwise specified, in cases where the variation was sufficiently low, we only look at the mean of the statistic**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results. \n",
    "Ensure to perform a correct experimental analysis (e.g. repeated experiments,\n",
    "statistical analysis of results)\n",
    "\n",
    "\n",
    "Report on: Generally this is a very good way of obtaining uncertainty estimates\n",
    "\n",
    "Then go for the singular ones, but mention that obviously there is an infinite possibility to combine all of the models, so this is only a point estimate (bwahahaha)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Conclusion. \n",
    "Is your line of work worth pursuing? What additional enhancements could be made?\n",
    "\n",
    "\n",
    "- YES! generally amazing\n",
    "\n",
    "- In more detail have to look that the techniques and whihc one is fitting for the task at hand\n",
    "\n",
    "- Watch out for more of this\n",
    "\n",
    "- Deep Learning can be used in this!\n",
    "\n",
    "- Make sure to have uncorrelated models, otherwise you're deceiving yourself\n",
    "\n",
    "- Theoretically can combine different kinds of models and can thus be used for other things (deep learning and linear combined results in A little Explainability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A short description of the contribution and self-evaluation of each member of the team\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URL address where we can find implementation of algorithms developed and used during the project: 1) source code, together with all data necessary to run the program and a short manual describing how to use/run the program, and 2) a sample run, screenshot, or other indication of system behaviour.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
